{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nurfaiz88/Google-Colab/blob/main/Day4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DAY 3\n",
        "\n",
        "#NUMPY#NUMERICAL PYTHON#ARRAY\n",
        "#For an RGB image, the pixel values are stored as a 3-dimensional array\n",
        "import numpy as np\n",
        "a=([1,2,3],[4,5,6])\n",
        "b=np.array(a)\n",
        "print(b)\n",
        "print(b.shape)\n",
        "print(b.ndim)\n",
        "print(b.itemsize)\n",
        "print(b.size)\n",
        "print(type(b))\n",
        "print(b.dtype)"
      ],
      "metadata": {
        "id": "zr6LDv1-mEbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 1\n",
        "import numpy as np\n",
        "x=np.array([1,2,3,4,5,6,7,8,9,10])\n",
        "print(x)\n",
        "a1=x.astype(int)\n",
        "print(a1)\n",
        "print(a1.dtype)\n",
        "a2=x.astype(float)\n",
        "print(a2)\n",
        "print(a2.dtype)"
      ],
      "metadata": {
        "id": "hy5tyjAzmHXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 2\n",
        "import numpy as np\n",
        "x=(range(4),range(10,14))\n",
        "arr=np.array(x)\n",
        "print(arr)\n",
        "print(arr.shape)\n",
        "print(arr.size)\n",
        "print(np.amax(arr))\n",
        "print(np.amin(arr))"
      ],
      "metadata": {
        "id": "bG2SXt5pmKRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 3:\n",
        "import numpy as n\n",
        "x=([1,2,3],[4,5,6],[7,8,9])\n",
        "arr=n.array(x)\n",
        "print(arr)\n",
        "print(arr.shape)\n",
        "print(arr.size)\n",
        "print(n.amax(arr))\n",
        "print(n.amin(arr))\n",
        "print(arr.ndim)\n",
        "print(arr.itemsize)\n",
        "print(arr.dtype)\n",
        "s=n.ones((3,3))\n",
        "print(s)\n",
        "y=n.zeros((2,3,4))\n",
        "print(y)\n",
        "v=n.ones((2,3,4))\n",
        "print(v)\n",
        "f=n.arange(0,999,3)\n",
        "print(f)\n"
      ],
      "metadata": {
        "id": "CYldPaGbmRW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "ejTsE-gOmTFl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvVelbfkismR"
      },
      "outputs": [],
      "source": [
        "#SAMPLE:\n",
        "import numpy as n\n",
        "#v=n.ones((3,3))\n",
        "v=n.array([1,2,3])\n",
        "v2=n.array([1,1,1])\n",
        "C=v*v2#Not matrix multiplication\n",
        "print(C)\n",
        "m=v.dot(v2)#Matrix multiplication\n",
        "print(m)\n",
        "\n",
        "#SAMPLE 2\n",
        "import numpy as n\n",
        "v=n.array([1,0,1])\n",
        "v2=n.array([1,1,1])\n",
        "print(n.logical_or(v,v2))\n",
        "\n",
        "#Exercise 4:\n",
        "import numpy as n\n",
        "a=n.array([0,0,0,0,1])\n",
        "b=n.array([1,1,1,1,0])\n",
        "print(n.logical_and(a,b))\n",
        "print(n.logical_not(a==0))\n",
        "print(n.logical_not(b==0))\n",
        "\n",
        "a=np.arange(12).reshape(3,4)\n",
        "print(a)\n",
        "b1=np.array([False,True,True])\n",
        "b2=np.array([True,False,True,False])\n",
        "z=a[b1,:]\n",
        "z1=a[:,b2]\n",
        "print(a[b1,b2])\n",
        "\n",
        "#Exercise 5:\n",
        "import numpy as np\n",
        "arr=np.array([0,1,2,3,4,5,6,7,8,9])\n",
        "x=arr<3\n",
        "print(x)#prints the boolean values in the array that satisy the condition\n",
        "y=arr[arr<3]\n",
        "print(y)#prints the values in the array that satisy the condition\n",
        "z=((arr < 3) | (arr > 8))\n",
        "print(z)\n",
        "print(arr[z])\n",
        "result = np.where(((arr < 3) | (arr > 8)),arr*5,arr*-5)\n",
        "print(result)\n",
        "\n",
        "\n",
        "#Exercise 6:\n",
        "import numpy as np\n",
        "a=np.array([range(4),range(10,14)])\n",
        "b=np.array([2,-1,1,0])\n",
        "c=a*b\n",
        "print(c)\n",
        "b1=b*100\n",
        "b2=b*100.0\n",
        "print(b1)\n",
        "print(b2)\n",
        "print(b1==b2)\n",
        "print(b1.dtype)\n",
        "print(b2.dtype)\n",
        "\n",
        "from numpy import array\n",
        "var = np.array( [1, 3, 5] )\n",
        "print('var = ' , var)\n",
        "s = var.sum()\n",
        "print('Sum result = ' , s)\n",
        "\n",
        "1 2 3   \n",
        "4 5 6\n",
        "1 2 3\n",
        ".sum=27\n",
        "6\n",
        "15\n",
        "6\n",
        "\n",
        "6 9 12\n",
        "\n",
        "\n",
        "x = np.array([[1, 1], [2, 2]])\n",
        "x.sum(axis=0)   # columns (first dimension)\n",
        "x[:, 0].sum(), x[:, 1].sum()\n",
        "x.sum(axis=1)   # rows (second dimension)\n",
        "x[0, :].sum(), x[1, :].sum()\n",
        "\n",
        "\n",
        "x = np.array([1, 3, 2])\n",
        "x.min()\n",
        "x.max()\n",
        "x.argmin()  \n",
        "x.argmax() \n",
        "\n",
        "\n",
        "x = np.array([1, 2, 3, 1])\n",
        "y = np.array([[1, 2, 3], [5, 6, 1]])\n",
        "x.mean()\n",
        "\n",
        "np.median(x)\n",
        "\n",
        "np.median(y, axis=-1)       # last axis\n",
        "\n",
        "x.std()          \n",
        "#Exercise 8\n",
        "import numpy as np\n",
        "#a=np.random.randint(size=(100,100))\n",
        "#a1=np.array(a)\n",
        "#print(a1)\n",
        "\n",
        "a=np.random.randint(low=20,high=50,size=(100,100))#make all elements bigger than 20 and smaller than 50 equal to -1\n",
        "print(a)\n",
        "a1=a[1:4,1:5]#Exract a sub matrix\n",
        "print(a1)\n",
        "\n",
        "\n",
        "#Exercise 9\n",
        "arr=np.arange(8)\n",
        "print(arr)\n",
        "arr1=arr.reshape(2,2,2)\n",
        "print(arr1)\n",
        "print(arr1.T)\n",
        "print(arr1.ravel())\n",
        "print(arr1.astype(float))\n",
        "#Deep Copy\n",
        "import numpy as np\n",
        "a=np.arange(12)\n",
        "print('Before')\n",
        "print(a)\n",
        "b=a\n",
        "b[0]=500\n",
        "print('After')\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "\n",
        "#Shallow Copy\n",
        "import numpy as np\n",
        "a=np.arange(12)\n",
        "print('Before')\n",
        "print(a)\n",
        "b=a.copy()\n",
        "b[0]=500\n",
        "print('After')\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "\n",
        "#PANDAS\n",
        "#PANDAS\n",
        "#Create Series from the list\n",
        "import pandas as pd\n",
        "print(pd.Series([1,3,5,6]))\n",
        "print(pd.Series([1,3,5,6],index=['A1','A2','A3','A4']))\n",
        "#Create series from np as array\n",
        "a=np.random.randn(100)*5+100\n",
        "date=pd.date_range('20170101',periods=100)\n",
        "s=pd.Series(a,index=date)\n",
        "print(s)\n",
        "#Create Series from Dictionary\n",
        "a2={'A1':5,'A2':3,'A3':6,'A4':2}\n",
        "s1=pd.Series(a2)\n",
        "print(s1)\n",
        "#Series Arithmetic\n",
        "a3=pd.Series([1,2,3,4],index=['a','b','c','d'])\n",
        "a4=pd.Series([4,3,2,1],index=['d','c','b','a'])\n",
        "print(a3+a4)\n",
        "print(a3-a4)\n",
        "print(a3*a4)\n",
        "print(a3/a4)\n",
        "#Series Attributes\n",
        "print(a3.index)\n",
        "print(a3.values)\n",
        "print(len(a3))\n",
        "#viewing Series Data\n",
        "print(s.head())\n",
        "print(s.head(10))\n",
        "print(s.tail())\n",
        "print(s.tail(5))\n",
        "#Selecting Data\n",
        "print(a3['b'])\n",
        "print(a3[2])\n",
        "print(a3[['b','d']])#multiple select by label\n",
        "print(a3[[1,3]])#multiple select by index integer\n",
        "\n",
        "#Slicing Seriees Data\n",
        "print(a3[1:4])#Slice items 1to 4\n",
        "print(a3[:4])\n",
        "print(a3[2:])\n",
        "\n",
        "#Exercise 9\n",
        "date=pd.date_range('20170101',periods=20)\n",
        "s=pd.Series(np.random.randn(20),index=date)\n",
        "print(s)\n",
        "print(s['2017-01-05':'2017-01-10'])\n",
        "\n",
        "# Create Data Frame from the list\n",
        "d=[[1,2],[3,4]]\n",
        "df=pd.DataFrame(d,index=[1,2],columns=['e','f'])\n",
        "print(df)\n",
        "#Create DF from Numpy Array\n",
        "d=np.arange(24).reshape(6,4)\n",
        "df=pd.DataFrame(d,index=np.arange(1,7),columns=list('ABCD'))\n",
        "print(df)\n",
        "#Create DF from Dictionary\n",
        "print(pd.DataFrame({'name':['Ally','Jane','Belinda'],'height':[160,155,163]},columns=['name','height'],index=['A1','A2','A3']))\n",
        "#Create DataFrame from np as array\n",
        "date=pd.date_range('20170101',periods=6)\n",
        "s=pd.Series(np.random.randn(6),index=date)\n",
        "s1=pd.Series(np.random.randn(6),index=date)\n",
        "df=pd.DataFrame({'Asia':s,'Europe':s1})\n",
        "print(df)\n",
        "#Exercise\n",
        "v=pd.DataFrame({'name':['Ally','Jane','Belinda'],'height':[160,155,163],'age':[40,35,42]},columns=['name','height','age'],index=['A1','A2','A3'])\n",
        "print(v)\n",
        "print(v.shape)\n",
        "print(v.columns)\n",
        "print(v.index)\n",
        "print(v.values)\n",
        "#Append a new column\n",
        "v['weight']=[45,56,44]\n",
        "print(v)\n",
        "#or\n",
        "v.insert(0,'id',[1,2,3])\n",
        "print(v)\n",
        "#Series Arithmetic\n",
        "a3=[[3,4],[5,6]]\n",
        "a4=[[6,5],[4,3]]\n",
        "b3=pd.DataFrame(a3,index=[1,2],columns=['d','b'])\n",
        "b4=pd.DataFrame(a4,index=[3,2],columns=['c','b'])\n",
        "print(b3)\n",
        "print(b4)\n",
        "print(b3+b4)\n",
        "#Viewing Data\n",
        "d=pd.DataFrame(np.random.randn(20,5))\n",
        "print(d.head())\n",
        "print(d.head(5))\n",
        "print(d.tail())\n",
        "print(d.tail(5))\n",
        "#Selecting Data\n",
        "print(v.iloc[2])#determine by position\n",
        "print(v.loc['A1'])#determine by key label\n",
        "#Slicing Seriees Data\n",
        "print(v[0:1])#Slicing here only 0th item will be shown\n",
        "print(v[:2])#here values until previous position to 2 will be displayed\n",
        "print(v[2:])#values including 2 until last position-1 will be displayed\n",
        "print(v.loc['A1']['height'])#Extract only with label A1 and column value height\n",
        "print(v.iloc[2]['height'])#Extract value in position 2 at the column height\n",
        "\n",
        "\n",
        "#CSV\n",
        "\n",
        "r=pd.read_csv(\"C:/Users/arun/Desktop/iris.csv\")\n",
        "print(r)\n",
        "print(r.head())\n",
        "print(r.columns)\n",
        "print(r.sepal_length[1:21])#Print only sepal length for first 20 values\n",
        "\n",
        "#Excel\n",
        "import pandas as pd\n",
        "df = pd.read_excel(\"C:/Users/arun/Desktop/itrain python/iris.xls\")\n",
        "print(df.head(10))\n",
        "\n",
        "\n",
        "#Filtering series from np as array\n",
        "a=np.random.randn(10)*4+5\n",
        "date=pd.date_range('20170101',periods=10)\n",
        "s=pd.Series(a,index=date)\n",
        "print(s>5)#Print the boolean results\n",
        "print(s[s>5])#print the value results\n",
        "\n",
        "\n",
        "# Filtering Dataframe\n",
        "r=pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data')\n",
        "attributes = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
        "r.columns = attributes\n",
        "print(r.head())\n",
        "print(r.columns)\n",
        "print(r.sepal_length[(r.species=='Iris-virginica')& (r.sepal_length >5.0)])#Prints the sepal length values for the species Iris Virginica and of sepal length >5.0\n",
        "\n",
        "#HANDLING MISSING VALUES\n",
        "\n",
        "missing=np.nan\n",
        "s=pd.Series([3,4,missing,6,missing,8])\n",
        "s.isnull()\n",
        "\n",
        "mydata=pd.read_csv(\"C:/Users/arun/Desktop/itrain python/python/Titanic.csv\")\n",
        "print(mydata.head(5))\n",
        "print(mydata.info())\n",
        "# To check  Any missing values?\n",
        "print(mydata.isnull().values.any())\n",
        "#Counting missing data\n",
        "mydata.isnull().sum()\n",
        "#Filling the missing values with 0\n",
        "z=mydata.fillna(0)\n",
        "z.isnull().sum()#Counting missing data\n",
        "#Fill the missing values with the previous value\n",
        "y=mydata.fillna(method='ffill')\n",
        "print(y.head(5))\n",
        "m=mydata.fillna(method='bfill')#Fill the missing values with the next value\n",
        "print(m.head(5))\n",
        "#Remove na rows \n",
        "s=mydata.dropna()\n",
        "print(s.head(5))\n",
        "#Remove  columns having NA values \n",
        "f=mydata.dropna(axis=1)\n",
        "print(f.head(5))\n",
        "mydata.dropna(how='all')#Identify the rows that conatin all missing values \n",
        "\n",
        "# Duplicates\n",
        "#Check for duplicates\n",
        "print(mydata.duplicated())\n",
        "#If duplicates present we can drop the duplicates by\n",
        "c=mydata.drop_duplicates()\n",
        "print(c)\n",
        "\n",
        "\n",
        "#CONCAT Series\n",
        "s1=pd.Series(['a','b'])\n",
        "s2=pd.Series(['c','d'])\n",
        "s3=pd.concat([s1,s2])\n",
        "s3=pd.concat([s1,s2],keys=['s1','s2'])\n",
        "print(s3)\n",
        "\n",
        "#CONCAT DATAFRAME\n",
        "data1 = {\n",
        "        'id': ['1', '2', '3', '4', '5'],\n",
        "        'Feature1': ['A', 'C', 'E', 'G', 'I'],\n",
        "        'Feature2': ['B', 'D', 'F', 'H', 'J']}\n",
        "dataf1 = pd.DataFrame(data1, columns = ['id', 'Feature1', 'Feature2'])\n",
        "print(dataf1)\n",
        "data2 = {\n",
        "        'id': ['1', '2', '6', '7', '8'],\n",
        "        'Feature1': ['K', 'M', 'O', 'Q', 'S'],\n",
        "        'Feature2': ['L', 'N', 'P', 'R', 'T']}\n",
        "dataf2 = pd.DataFrame(data2, columns = ['id', 'Feature1', 'Feature2'])\n",
        "print(dataf2)\n",
        "data3 = {\n",
        "        'id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
        "        'Feature3': [12, 13, 14, 15, 16, 17, 15, 12, 13, 23]}\n",
        "dataf3 = pd.DataFrame(data3, columns = ['id', 'Feature3'])\n",
        "print(dataf3)\n",
        "dataconcat=pd.concat([dataf1,dataf2])\n",
        "print(dataconcat)#just concats as it is 0,1,2,3,4,0,1,2,3,4\n",
        "dataconcat=pd.concat([dataf1,dataf2],ignore_index=True)\n",
        "print(dataconcat)#concats by ignoring the index 0,1,2,3,4,5,6,7,8,9\n",
        "dataconcat=pd.concat([dataf1,dataf2],keys=['x','y'])#concatthe data frame with unique keys for each dataframe\n",
        "print(dataconcat)\n",
        "print(dataconcat.loc['y'])\n",
        "dconcolumn=pd.concat([dataf1,dataf2],axis=1)#concatenate DataFrames along column\n",
        "print(dconcolumn)\n",
        "#join\n",
        "dajoin1=pd.merge(dataf1,dataf2,on='id',how='inner')\n",
        "print(dajoin1)#prints only the rows that has common id in both data frames\n",
        "dajoin2=pd.merge(dataf1,dataf2,on='id',how='outer')\n",
        "print(dajoin2)#just merge two dataframes replacing Nan for the id that is not in the dataframe\n",
        "#Sorting in dataframe\n",
        "import numpy as np\n",
        "d=np.random.randn(24).reshape(12,2)\n",
        "print(d)\n",
        "df=pd.DataFrame(d,columns=['a','b'])\n",
        "print(df)\n",
        "df1=df.sort_values(by=['a'])\n",
        "print(df1)\n",
        "\n",
        "#GROUP BY\n",
        "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
        "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
        "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
        "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
        "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
        "df = pd.DataFrame(ipl_data)\n",
        "print(df)\n",
        "print(df.describe())\n",
        "df1=df.groupby('Team')\n",
        "print(df1.groups)\n",
        "print(df1.max())\n",
        "df2=df.groupby('Year')\n",
        "print(df2['Points'].agg(np.mean))\n",
        "\n",
        "#Covariance is a measure of relationship between 2 variables. It measures the degree of change in the variables, i.e. when one variable changes, will there be the same/a similar change in the other variable. \n",
        "s=df[['Points','Rank']].cov()\n",
        "print(s)\n",
        "#Correlation (-1 to 1)\n",
        "v=df[['Points','Rank']].corr()\n",
        "print(v)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "print (pd.Series([1,3,5,6]))\n",
        "print(pd.Series([1,3,5,6],index=['A1','A2','A3','A4']))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "a = np.random.randn(100)*5+100\n",
        "date =pd.date_range('20170101',periods=100)\n",
        "s = pd.Series(a,index=date)\n",
        "print (s)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "a = {'A1':5,'A2':3,'A3':6,'A4':2}\n",
        "s = pd.Series(a)\n",
        "print (a)\n",
        "\n",
        "\n",
        "a = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
        "b = pd.Series([4, 3, 2, 1], index=['d', 'c', 'b', 'a'])\n",
        "a + b # different from Python list\n",
        "a - b\n",
        "a * b\n",
        "a/b\n",
        "\n",
        "a.index\n",
        "a.values\n",
        "len(a)\n",
        "a.head()# first 5 rows\n",
        "a.head(3)# first 3 rows\n",
        "a.tail()# last 5 rows\n",
        "a.tail(2)#last 2 rows\n",
        "print(b.iloc[3])\n",
        "print(a[['b','d']])#multiple select by label\n",
        "print(a[[1,3]])# multiple select by index integer\n",
        "print(a[2:5])\n",
        "print(a[2])\n",
        "print(a[[2]])\n",
        "\n",
        "#Exercise 9\n",
        "date=pd.date_range('20170101',periods=20)\n",
        "s=pd.Series(np.random.randn(20),index=date)\n",
        "print(s)\n",
        "print(s['2017-01-05':'2017-01-10'])\n",
        "\n",
        "\n",
        "start:end\n",
        "3:9\n",
        "3:8\n",
        "\n",
        "import pandas as pd\n",
        "d = [[1,2],[3,4]]\n",
        "df= pd.DataFrame(d,index=[1,2],columns=['a','b'])\n",
        "print (df)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "d = np.arange(24).reshape(6,4)\n",
        "df = pd.DataFrame(d, index=np.arange(1,7), columns=list('ABCD'))\n",
        "print (df)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "v=pd.DataFrame(\n",
        "{\n",
        "'name': ['Ally','Jane','Belinda'],\n",
        "'height':[160,155,163],\n",
        "},\n",
        "columns = ['name','height'],\n",
        "index = ['A1','A2','A3'])\n",
        "v\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "date = pd.date_range('20170101',periods=6)\n",
        "s1 = pd.Series(np.random.randn(6),index=date)\n",
        "s2 = pd.Series(np.random.randn(6),index=date)\n",
        "df = pd.DataFrame({'Asia':s1,'Europe':s2})\n",
        "print (df)\n",
        "\n",
        "print(v)\n",
        "print(v.shape)\n",
        "print(v.columns)\n",
        "print(v.index)\n",
        "print(v.values)\n",
        "#Append a new column\n",
        "v['weight']=[45,56,44]\n",
        "print(v)\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd a = [[3,4],[5,6]] b = [[6,5],[4,3]] a2 = pd.DataFrame(a,index=[1,2],columns=['d','b']) b2 = pd.DataFrame(b,index=[3,2],columns=['c','b']) print(a2+b2)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "a = pd.DataFrame(np.random.randn(20,5))\n",
        "print (a.head())\n",
        "print (a.head(5))\n",
        "print (a.tail())\n",
        "print (a.tail(5))\n",
        "\n",
        "\n",
        "df[['name','height']]\n",
        "df.name\n",
        "df[[1,2]]\n",
        "\n",
        "\n",
        "print(v.iloc[0])\n",
        "print(v.loc['Apple1']) \n",
        "\n",
        "df.iloc[1:3]\n",
        "df.iloc[1:]\n",
        "df.iloc[:3]\n",
        "\n",
        "\n",
        "df.loc['A1']['height']\n",
        "df.iloc[1]['height']\n",
        "\n",
        "\n",
        "#IMPORT EXCEL DATA\n",
        "sp500=pd.read_excel('C:/Users/arun/Desktop/ITRAIN/Saranya/Saranya/sp500.xlsx')\n",
        "sp500.head()\n",
        "\n",
        "#import csv file\n",
        "df = pd.read_csv('C:/Users/arun/Desktop/ITRAIN/Saranya/Saranya/Social Influence on Shopping.csv')\n",
        "df.head()\n",
        "\n",
        "#Exercise\n",
        "df1 = pd.read_csv('C:/Users/arun/Desktop/ITRAIN/Saranya/Saranya/twitter_airline_sentiment.csv')\n",
        "df1.head()\n",
        "df1.info()\n",
        "df1.columns\n",
        "\n",
        "df = pd.DataFrame([[2, 2, 2, 0],\n",
        "[3, 3, 4, 4],\n",
        "[3, 8, 5, 5],\n",
        "[3, 3, 4, 4]],\n",
        "columns = ['A', 'B', 'C', 'D'])\n",
        "df.duplicated()\n",
        "df.drop_duplicates()\n",
        "df.drop_duplicates('A')\n",
        "\n",
        "print(df1.duplicated())\n",
        "print(df1.drop_duplicates())\n",
        "\n",
        "print(df1.isnull().sum())\n",
        "\n",
        "print(\"Percentage null or na values in df\")\n",
        "((df1.isnull() | df1.isna()).sum() * 100 / df1.index.size).round(2)\n",
        "#tweet_coord , airline_sentiment_gold, negativereason_gold have more than 90% missing data. It will be better to delete these columns as they will not provide any constructive information.\n",
        "\n",
        "\n",
        "del df1['tweet_coord']\n",
        "del df1['airline_sentiment_gold']\n",
        "del df1['negativereason_gold']\n",
        "df1.head()\n",
        "\n",
        "sp500=pd.read_excel('C:/Users/arun/Desktop/ITRAIN/Saranya/Saranya/sp500.xlsx',index_col ='Symbol', usecols=['Symbol','Sector','Price']))\n",
        "sp500.head()\n",
        "\n",
        "sp500[sp500.Price > 100]\n",
        "sp500[sp500.Price == sp500.Price.max()]\n",
        "sp500[(sp500.Price < 10) & (sp500.Price > 0)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df = pd.DataFrame([[2, 2, 2, 0],\n",
        "[3, 3, 4, 4],\n",
        "[3, 8, 5, 5],\n",
        "[3, 3, 4, 4]],\n",
        "columns = ['A', 'B', 'C', 'D'])\n",
        "df.duplicated()\n",
        "df.drop_duplicates()\n",
        "df.drop_duplicates('A')\n",
        "\n",
        "by=desc\n",
        "\n",
        "sp500 = pd.read_excel('C:/Users/arun/Desktop/ITRAIN/Saranya/Saranya/sp500.xlsx',index_col ='Symbol', usecols=['Symbol','Sector','Price'])\n",
        "sp500[sp500.Price > 100]\n",
        "sp500[sp500.Price == sp500.Price.max()]\n",
        "sp500[(sp500.Price < 10) & (sp500.Price > 0)]\n",
        "\n",
        "#GROUP BY\n",
        "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
        "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
        "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
        "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
        "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
        "df = pd.DataFrame(ipl_data)\n",
        "print(df)\n",
        "print(df.describe())\n",
        "df1=df.groupby('Team')\n",
        "print(df1.groups)\n",
        "print(df1.max())\n",
        "df2=df.groupby('Year')\n",
        "print(df2['Points'].agg(np.mean))\n"
      ],
      "metadata": {
        "id": "KHfk2QQ0jAaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot\n",
        "\n",
        "\n",
        "#CHART PROPERTIES\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "x = np.arange(0,10) \n",
        "print(x)\n",
        "y = x**2 \n",
        "print(y)\n",
        "#Labeling the Axes and Title\n",
        "plt.title(\"Graph Drawing\") \n",
        "plt.xlabel(\"Time\") \n",
        "plt.ylabel(\"Distance\") \n",
        "# Formatting the line colors\n",
        "#Line plot is mainly used to visualize a trend in data over intervals of time \n",
        "plt.plot(x,y,'r')\n",
        "plt.plot(x,y,'bs')\n",
        "plt.plot(x,y,'g^')\n",
        "# Formatting the line type  \n",
        "plt.plot(x,y,'>')\n",
        "#Sample\n",
        "plt.figure(figsize=(15,5))#specify the size of the figure using method figure() with the values as the length of rows and columns \n",
        "plt.plot([1,2,3],[4,5,1])\n",
        "#Multiple plots in one fiqure\n",
        "x=np.arange(1,5)\n",
        "print(x)\n",
        "y=x**3\n",
        "print(y)\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(x,y,'r^')\n",
        "plt.title('\\n1stSubplot')\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot([1,2,3,4],[1,4,9,16],'go')\n",
        "plt.title('2ndSubplot')\n",
        "plt.suptitle(\"My Sub plot\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#DIFFERENT GRAPHS\n",
        "#BAR GRAPH\n",
        "#The x-axis represents the categories and are spaced evenly. The y-axis represents the quantity for each category \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "# Our data\n",
        "labels = [\"JavaScript\", \"Java\", \n",
        "\"Python\", \"C#\"]\n",
        "usage = [69.8, 45.3, 38.8, 34.4]\n",
        "# Creating our bar plot\n",
        "plt.bar(labels, usage,color=\"red\")\n",
        "plt.xlabel(\"Programming language\")\n",
        "plt.ylabel(\"Usage (%)\")\n",
        "plt.title(\"Programming language usage\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#SCATTER PLOT\n",
        "#A scatter plot (or ‘scatterplot’) is generally used to summarize the relationship between two paired data samples.\n",
        "#Paired data samples means that two measures were recorded for a given observation, such as the weight and height of a person.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "temp = [30, 32, 33, 28.5, 35, 29, 29]\n",
        "ice_creams_count = [100, 115, 115, 75, 125, 79, 89]\n",
        "#plt.plot(temp, ice_creams_count)\n",
        "plt.scatter(temp, ice_creams_count)\n",
        "plt.title(\"Temperature vs. Sold ice creams\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Sold ice creams count\")\n",
        "plt.show()\n",
        "\n",
        "#histogram\n",
        "#Histogram plot is generally used to summarize the distribution of a data sample.\n",
        "#The x-axis represents discrete bins or intervals for the observations.\n",
        "import pandas as pd\n",
        "r=pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data')\n",
        "attributes = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
        "r.columns = attributes\n",
        "r.hist(bins=12,color='red')\n",
        "plt.show()\n",
        "\n",
        "#Pie Chart\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "sizes = [25, 20, 45, 10]\n",
        "labels = [\"Cats\", \"Dogs\", \"Tigers\", \"Goats\"]\n",
        "plt.pie(sizes, labels = labels, autopct = \"%.2f\")\n",
        "plt.show()\n",
        "\n",
        "#Violin PLot\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "r=pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data')\n",
        "attributes = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
        "r.columns = attributes\n",
        "sns.violinplot(x='species',y='petal_length', data=r)\n",
        "plt.show()\n",
        "\n",
        "#HEATMAPS\n",
        "# Create a dataset \n",
        "df = pd.DataFrame(np.random.random((5,5)), columns=[\"a\",\"b\",\"c\",\"d\",\"e\"])\n",
        "print(df)\n",
        "# Default heatmap: just a visualization of this square matrix\n",
        "p1 = sns.heatmap(df)\n",
        "\n",
        "\n",
        "#BOXPLOT\n",
        "sns.boxplot( y=r[\"sepal_length\"] )\n",
        "plt.show()\n",
        "sns.boxplot( x=r[\"species\"], y=r[\"sepal_length\"] )\n",
        "plt.show()\n",
        "\n",
        "#Swarm plot\n",
        "sns.swarmplot(x='species',y='petal_length', data=r)\n",
        "plt.show()\n",
        "\n",
        "#Distribution plot\n",
        "x = np.random.randn(100)\n",
        "ax = sns.distplot(x)\n",
        "\n",
        "#Rug plot\n",
        "ax=sns.distplot()\n",
        "ax = sns.distplot(x, rug=True, hist=False)\n",
        "\n",
        "#Joint Plot\n",
        "import seaborn as sns\n",
        "g = sns.jointplot(\"sepal_width\", \"petal_length\", data=r, color=\"g\")\n",
        " \n",
        "#Pair plot\n",
        "sns.pairplot(r)\n",
        "\n",
        "\n",
        "#countplot\n",
        "sns.countplot(x=\"species\",data=r)\n",
        "\n",
        "\n",
        "#Strip plot\n",
        "sns.stripplot(x='species',y='petal_length', data=r,jitter=0.5)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#BASIC ANNOTATION\n",
        "import numpy as np\n",
        "x = np.arange(0,10) \n",
        "y = x ^ 2 \n",
        "z = x ^ 3\n",
        "t = x ^ 4 \n",
        "# Labeling the Axes and Title\n",
        "plt.title(\"Graph Drawing\") \n",
        "plt.xlabel(\"Time\") \n",
        "plt.ylabel(\"Distance\") \n",
        "plt.plot(x,y)\n",
        "\n",
        "#Annotate\n",
        "plt.annotate(xy=[2,1], s='Second Entry') \n",
        "plt.annotate(xy=[4,6], s='Third Entry') "
      ],
      "metadata": {
        "id": "wE-xIGztjMpn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}